# ÐÐµÐ¹Ñ€Ð¾ÑÐµÑ‚ÐµÐ²Ð¾Ð¹ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð´Ð»Ñ Ð¼Ð°ÑˆÐ¸Ð½Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ

## ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ

### ÐžÐ±Ð·Ð¾Ñ€ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñ‹
Ð‘Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ° Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ ÑÑ‚ÐµÐº Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð½ÐµÐ¹Ñ€Ð¾Ð½Ð½Ñ‹Ñ… ÑÐµÑ‚ÐµÐ¹. ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹:

#### 1. DataSetLoader ðŸ—‚ï¸
**ÐÐ°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ:** Ð Ð°Ð±Ð¾Ñ‚Ð° Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸

| ÐœÐµÑ‚Ð¾Ð´                | ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹               | Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ | ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ                                                                 |
|-----------------------|-------------------------|------------|-------------------------------------------------------------------------|
| `__init__`            | ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°       | -          | ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° iris/mnist/diabetes                             |
| `load_dataset`        | ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°       | -          | Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² Ð¿Ð°Ð¼ÑÑ‚ÑŒ                                                |
| `get_stats`           | -                       | Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ    | Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÑ€ÐµÐ´Ð½Ð¸Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð¸ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ðµ Ð¾Ñ‚ÐºÐ»Ð¾Ð½ÐµÐ½Ð¸Ñ                    |
| `head`/`tail`        | ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¾Ð±Ñ€Ð°Ð·Ñ†Ð¾Ð²     | ÐšÐ¾Ñ€Ñ‚ÐµÐ¶     | ÐŸÐµÑ€Ð²Ñ‹Ðµ/Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ n Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð¾Ð² Ð´Ð°Ð½Ð½Ñ‹Ñ…                                      |
| `info_small`          | -                       | -          | ÐšÑ€Ð°Ñ‚ÐºÐ°Ñ ÑÐ²Ð¾Ð´ÐºÐ°: Ñ€Ð°Ð·Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚Ð¸ Ð¸ Ð¿Ñ€Ð¸Ð¼ÐµÑ€ Ð´Ð°Ð½Ð½Ñ‹Ñ…                             |
| `info_full`           | -                       | -          | ÐŸÐ¾Ð»Ð½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ñ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸ÐµÐ¼ Ð¼ÐµÑ‚Ð¾Ðº Ð¸ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸ÐµÐ¼ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²          |
| `shuffle`             | -                       | -          | ÐŸÐµÑ€ÐµÐ¼ÐµÑˆÐ¸Ð²Ð°Ð½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸ÐµÐ¼ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸ Ð¼ÐµÑ‚Ð¾Ðº          |
| `batch`               | Ð Ð°Ð·Ð¼ÐµÑ€ Ð±Ð°Ñ‚Ñ‡Ð°            | Ð“ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€  | Ð˜Ñ‚ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ð°Ñ Ð²Ñ‹Ð´Ð°Ñ‡Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾Ñ€Ñ†Ð¸ÑÐ¼Ð¸                                      |
| `map`                 | Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ  | -          | ÐŸÑ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ ÐºÐ¾ Ð²ÑÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ð¼                                       |
| `filter`              | Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ-Ñ„Ð¸Ð»ÑŒÑ‚Ñ€          | -          | Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð¾Ð±Ñ€Ð°Ð·Ñ†Ð¾Ð² Ð½Ðµ ÑƒÐ´Ð¾Ð²Ð»ÐµÑ‚Ð²Ð¾Ñ€ÑÑŽÑ‰Ð¸Ñ… ÑƒÑÐ»Ð¾Ð²Ð¸ÑŽ                           |
| `split`               | Ð Ð°Ð·Ð¼ÐµÑ€ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸ | ÐšÐ¾Ñ€Ñ‚ÐµÐ¶     | Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð½Ð° train/test                                                |
| `standard_scaler`     | -                       | -          | ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾ z-Ð¾Ñ†ÐµÐ½ÐºÐµ                                         |

---

### 2. ActivationFunction âš¡
**Ð ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸:**

```python
# ReLU
forward(x) = max(0, x) 
backward(x) = 1 ÐµÑÐ»Ð¸ x > 0, Ð¸Ð½Ð°Ñ‡Ðµ 0

# Sigmoid
forward(x) = 1 / (1 + e^(-x))
backward(x) = Ïƒ(x) * (1 - Ïƒ(x))

# Tanh
forward(x) = (e^x - e^(-x)) / (e^x + e^(-x))
backward(x) = 1 - tanhÂ²(x)

# LeakyReLU
forward(x) = x (x > 0), 0.01x (x <= 0)
backward(x) = 1 (x > 0), 0.01 (x <= 0)
```

---

### 3. Optimizer ðŸŽ¯
**Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ‹:**

| ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ‚Ð¾Ñ€    | ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹                          | Ð¤Ð¾Ñ€Ð¼ÑƒÐ»Ð° Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ                     |
|---------------|-----------------------------------|----------------------------------------|
| SGD           | `learning_rate`                  | `w = w - Î·*âˆ‡`                          |
| MomentumSGD    | `learning_rate`, `momentum`       | `v = Î³*v + Î·*âˆ‡`, `w = w - v`           |
| RMSprop        | `learning_rate`, `decay_rate`     | `E[gÂ²] = ÏE[gÂ²] + (1-Ï)gÂ²`, `w = w - Î·*g/âˆš(E[gÂ²]+Îµ)` |
| Adam           | `learning_rate`, `beta1`, `beta2` | ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð°Ñ†Ð¸Ñ Momentum Ð¸ RMSprop Ñ bias correction |

---

### 4. Layer ðŸ§±
**ÐÑ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð°:**
```python
class Layer:
    def __init__(input_size, output_size, activation):
        self.weights = Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ xavier
        self.bias = Ð½ÑƒÐ»ÐµÐ²Ð¾Ð¹ Ð²ÐµÐºÑ‚Ð¾Ñ€
    
    # ÐŸÑ€ÑÐ¼Ð¾Ð¹ Ð¿Ñ€Ð¾Ñ…Ð¾Ð´
    def forward(inputs) â†’ outputs
    
    # ÐžÐ±Ñ€Ð°Ñ‚Ð½Ð¾Ðµ Ñ€Ð°ÑÐ¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ
    def backward(grad_output) â†’ grad_input
```

---

### 5. NeuralNetwork ðŸ§ 
**Ð Ð°Ð±Ð¾Ñ‡Ð¸Ð¹ Ñ†Ð¸ÐºÐ»:**
1. Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÐµÑ‚Ð¸ Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð¾Ð¼
```python
model = NeuralNetwork(Optimizer.Adam(lr=0.001))
```
2. Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÐ»Ð¾ÐµÐ²
```python
model.add_layer(Layer(4, 10, ActivationFunction.ReLU))
model.add_layer(Layer(10, 3, ActivationFunction.Softmax))
```
3. ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
```python
model.fit(X_train, y_train, epochs=100)
```
4. ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ
```python
predictions = model.predict(X_test)
```

---

## ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸
- **Ð“Ð¸Ð±ÐºÐ¾ÑÑ‚ÑŒ**: ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° ÐºÐ°ÑÑ‚Ð¾Ð¼Ð½Ñ‹Ñ… ÑÐ»Ð¾ÐµÐ² Ð¸ Ð°ÐºÑ‚Ð¸Ð²Ð°Ñ†Ð¸Ð¹
- **ÐŸÑ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ**: Ð’ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ñ Ñ‡ÐµÑ€ÐµÐ· numpy
- **ÐÐ½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ°**: Ð’ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ð¾Ð´Ñ‹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…
- **ÐœÐ¾Ð´ÑƒÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ**: ÐÐµÐ·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¾Ð²

## ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ
```python
# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°
dl = DataSetLoader('iris')
dl.shuffle()
X_train, X_test, y_train, y_test = dl.split(0.2)

# Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
model = NeuralNetwork(Optimizer.Adam(lr=0.01))
model.add_layer(Layer(4, 10, ActivationFunction.ReLU))
model.add_layer(Layer(10, 3, ActivationFunction.Sigmoid))

# ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
loss_history = model.fit(X_train, y_train, epochs=100)

# ÐžÑ†ÐµÐ½ÐºÐ°
accuracy = model.evaluate(X_test, y_test)
print(f"Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {accuracy:.2%}")
```
```